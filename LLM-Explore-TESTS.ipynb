{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f57144c4-8dae-44b5-a2bb-7172381fec03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "api key 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\n",
      "path C:\\Users\\nonak\\Documents\\Thoughts\\Drafts\\LLM-searches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Coletando arquivos Markdown...\n",
      "✅ 5 arquivos encontrados.\n",
      "\n",
      "\n",
      "🗓️ Data: 2025-04-14\n",
      "====================================================================================================\n",
      "\n",
      "📄 Resumo do arquivo: datascience-complete-ptbr.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **Título:** Entendendo como interpretamos e compartilhamos desinformação\n",
      "- **Principais tópicos:** Susceptibilidade à desinformação online, fatores demográficos, interpretação e compartilhamento de desinformação.\n",
      "- **Ideias centrais ou insights:** Explora a interpretação e compartilhamento de desinformação, contribuindo para estratégias eficazes de desmascaramento.\n",
      "- **Referências importantes:** [Entendendo como interpretamos e compartilhamos desinformação](https://www.psychologicalscience.org/publications/observer/interpret-share-misinformation.html)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📄 Resumo do arquivo: datascience_content_ideas-complete-ptbr.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **Título**: Perguntas sobre canais de YouTube de ciência de dados em 2024\n",
      "- **Principais tópicos**: Tendências, habilidades específicas, interação com o público, entrega de conteúdo, aplicação prática, atualização, níveis de habilidade, impacto na comunidade, colaboração, formatos inovadores.\n",
      "- **Ideias centrais ou insights**: Canais de YouTube de ciência de dados em 2024 focam em atualização, conteúdo prático, colaboração e diversidade de habilidades.\n",
      "- **Referências importantes**: Canais como 3Blue1Brown, Joma Tech e CS Dojo são fontes relevantes de conteúdo em ciência de dados e programação.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📄 Resumo do arquivo: data_science_projetc-complete-ptbr.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **Principais tópicos**:\n",
      "  - Listas de projetos de ciência de dados para iniciantes e especialistas.\n",
      "  - Ideias de projetos de fontes variadas como Built In, 365 Data Science, Reddit, GeeksforGeeks, Springboard, Medium, StrataScratch e Quora.\n",
      "  - Sugestões de projetos para portfólios e iniciantes.\n",
      "  - Orientação prática, conjuntos de dados, artigos de pesquisa, elementos interativos e recursos adicionais para exploração.\n",
      "  - Desafios comuns na implementação de projetos de ciência de dados, ideias inovadoras para 2025, uso de tecnologias emergentes e tendências na ciência de dados.\n",
      "  - Contribuição dos projetos de ciência de dados na resolução de desafios do mundo real, habilidades e ferramentas essenciais, manter-se atualizado com conferências e eventos, e principais ideias de projetos com código-fonte.\n",
      "\n",
      "- **Ideias centrais ou insights**:\n",
      "  - Diversidade de projetos de ciência de dados para diferentes níveis de habilidade e interesses.\n",
      "  - Importância da relevância no mundo real dos projetos para melhorar a experiência de aprendizado.\n",
      "  - Enfoque em soluções eficazes para desafios comuns, ideias inovadoras para 2025, utilização de tecnologias emergentes e contribuição dos projetos na sociedade.\n",
      "\n",
      "- **Referências importantes**:\n",
      "  - Built In, 365 Data Science, Reddit, GeeksforGeeks, Springboard, Medium, StrataScratch, ProjectPro.io.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📄 Resumo do arquivo: mental_health-complete-ptbr.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **Principais tópicos**:\n",
      "  - Benefícios do compartilhamento de conhecimento\n",
      "  - Importância do compartilhamento de conhecimento\n",
      "  - Exemplos e benefícios específicos de compartilhamento de conhecimento\n",
      "\n",
      "- **Ideias centrais ou insights**:\n",
      "  - Compartilhar conhecimento alinha equipes, engaja funcionários e promove inovação.\n",
      "  - O compartilhamento de conhecimento padroniza procedimentos e cria especialistas.\n",
      "  - Compartilhar conhecimento melhora o crescimento pessoal e profissional.\n",
      "\n",
      "- **Referências importantes**:\n",
      "  - Links para artigos sobre a importância e benefícios do compartilhamento de conhecimento.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📄 Resumo do arquivo: mental_helth-complete-ptbr.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **Título**: Diversos títulos abordando a exposição da vida pessoal online.\n",
      "- **Principais tópicos**: Motivações para compartilhar a vida pessoal online, equilíbrio entre autenticidade e privacidade, impacto nos relacionamentos, importância da auto-revelação online.\n",
      "- **Ideias centrais ou insights**: Encontrar equilíbrio na exposição online, reflexão sobre os motivos e impactos do compartilhamento, proteção dos relacionamentos pessoais.\n",
      "- **Referências importantes**: Scott Stratten, Scientific American, Medium, Fox Business, artigo de Lada Prkic.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import textwrap\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# ========================\n",
    "# CONFIGURAÇÕES\n",
    "# ========================\n",
    "\n",
    "openai.api_key = input('api key') # substitua pela sua chave\n",
    "CAMINHO_PASTA = input('path')\n",
    "MAX_CHARS = 4000\n",
    "\n",
    "# ========================\n",
    "# FUNÇÕES UTILITÁRIAS\n",
    "# ========================\n",
    "\n",
    "def coletar_markdowns(diretorio_base):\n",
    "    arquivos_md = []\n",
    "    for raiz, _, arquivos in os.walk(diretorio_base):\n",
    "        for arquivo in arquivos:\n",
    "            if arquivo.endswith(\".md\"):\n",
    "                caminho_completo = os.path.join(raiz, arquivo)\n",
    "                data_modificacao = datetime.fromtimestamp(os.path.getmtime(caminho_completo)).date()\n",
    "                arquivos_md.append({\n",
    "                    \"caminho\": caminho_completo,\n",
    "                    \"data\": data_modificacao\n",
    "                })\n",
    "    return arquivos_md\n",
    "\n",
    "def carregar_conteudo_arquivos(lista_arquivos):\n",
    "    conteudos = []\n",
    "    for item in lista_arquivos:\n",
    "        caminho = item[\"caminho\"]\n",
    "        try:\n",
    "            with open(caminho, 'r', encoding='utf-8') as f:\n",
    "                conteudos.append({\n",
    "                    \"caminho\": caminho,\n",
    "                    \"data\": item[\"data\"],\n",
    "                    \"conteudo\": f.read()\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao ler {caminho}: {e}\")\n",
    "    return conteudos\n",
    "\n",
    "def resumir_com_openai(texto, caminho, parte=None):\n",
    "    titulo_arquivo = os.path.basename(caminho)\n",
    "    parte_info = f\" (Parte {parte})\" if parte else \"\"\n",
    "    prompt = textwrap.dedent(f\"\"\"\n",
    "        Você é um assistente que resume arquivos Markdown de forma objetiva e concisa.\n",
    "        Resuma brevemente o conteúdo do arquivo: **{titulo_arquivo}{parte_info}**.\n",
    "\n",
    "        Formato do resumo:\n",
    "        - **Título** (se houver)\n",
    "        - **Principais tópicos**\n",
    "        - **Ideias centrais ou insights**\n",
    "        - **Referências importantes (se houver)**\n",
    "        \n",
    "        Seja direto, use frases curtas e foque apenas no essencial.\n",
    "\n",
    "        Texto:\n",
    "        {texto}\n",
    "    \"\"\")\n",
    "\n",
    "    try:\n",
    "        resposta = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Você é um assistente que resume arquivos Markdown com precisão e concisão.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=400  # Resumo mais curto\n",
    "        )\n",
    "        return resposta['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        return f\"[ERRO AO CONSULTAR LLM]: {e}\"\n",
    "\n",
    "\n",
    "def dividir_texto(texto, max_chars):\n",
    "    partes = []\n",
    "    while len(texto) > max_chars:\n",
    "        corte = texto[:max_chars].rfind(\"\\n\\n\")\n",
    "        if corte == -1:\n",
    "            corte = max_chars\n",
    "        partes.append(texto[:corte])\n",
    "        texto = texto[corte:]\n",
    "    partes.append(texto)\n",
    "    return partes\n",
    "\n",
    "def processar_arquivo(item):\n",
    "    caminho = item[\"caminho\"]\n",
    "    texto = item[\"conteudo\"]\n",
    "\n",
    "    partes = dividir_texto(texto, MAX_CHARS)\n",
    "    resumos_parciais = []\n",
    "\n",
    "    for idx, parte in enumerate(partes):\n",
    "        resumo = resumir_com_openai(parte, caminho, parte=(idx+1) if len(partes) > 1 else None)\n",
    "        resumos_parciais.append(resumo)\n",
    "\n",
    "    if len(resumos_parciais) > 1:\n",
    "        resumo_final = resumir_com_openai(\"\\n\\n\".join(resumos_parciais), caminho)\n",
    "    else:\n",
    "        resumo_final = resumos_parciais[0]\n",
    "\n",
    "    return resumo_final\n",
    "\n",
    "# ========================\n",
    "# MAIN\n",
    "# ========================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🔍 Coletando arquivos Markdown...\")\n",
    "    arquivos = coletar_markdowns(CAMINHO_PASTA)\n",
    "    print(f\"✅ {len(arquivos)} arquivos encontrados.\\n\")\n",
    "\n",
    "    conteudos = carregar_conteudo_arquivos(arquivos)\n",
    "\n",
    "    # Agrupar arquivos por data\n",
    "    arquivos_por_data = defaultdict(list)\n",
    "    for item in conteudos:\n",
    "        arquivos_por_data[item[\"data\"]].append(item)\n",
    "\n",
    "    # Ordenar por data decrescente\n",
    "    datas_ordenadas = sorted(arquivos_por_data.keys(), reverse=True)\n",
    "\n",
    "    for data in datas_ordenadas:\n",
    "        print(f\"\\n🗓️ Data: {data}\")\n",
    "        print(\"=\" * 100)\n",
    "        for item in arquivos_por_data[data]:\n",
    "            print(f\"\\n📄 Resumo do arquivo: {os.path.basename(item['caminho'])}\")\n",
    "            print(\"-\" * 80)\n",
    "            resumo = processar_arquivo(item)\n",
    "            print(resumo)\n",
    "            print(\"\\n\" + \"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4285c7f-0b88-487a-8e9b-ac9ce2f6c49e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
