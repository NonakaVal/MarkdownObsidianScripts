{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f57144c4-8dae-44b5-a2bb-7172381fec03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "api key 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\n",
      "path C:\\Users\\nonak\\Documents\\Thoughts\\Atlas\\03_SNIPPETS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Coletando arquivos Markdown...\n",
      "✅ 5 arquivos encontrados.\n",
      "\n",
      "\n",
      "🗓️ Data: 2025-05-03\n",
      "====================================================================================================\n",
      "\n",
      "📄 Resumo do arquivo: snip-openai-agent-llm-classificacao-v-df-pandas.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **Título**: Criação de um Agente de Classificação de Colunas em DataFrames Pandas\n",
      "- **Principais tópicos**:\n",
      "  - Função `classificar_dataframe` para classificar textos em um DataFrame usando a API da OpenAI\n",
      "  - Parâmetros da função e suas descrições\n",
      "  - Processamento em lote ou individualmente\n",
      "  - Solicitação de inputs do usuário para chave de API e prompt do sistema\n",
      "  - Utilização de prompt padrão se o usuário não fornecer um\n",
      "  - Classificação de um DataFrame com base em texto e sentimento\n",
      "- **Ideias centrais ou insights**:\n",
      "  - Função que classifica textos em um DataFrame usando a API da OpenAI, preenchendo uma coluna de classificação\n",
      "  - Configuração do modelo da OpenAI, instrução do sistema, aleatoriedade das respostas e tamanho do lote de processamento\n",
      "  - Possibilidade de inserir chave de API e prompt personalizado\n",
      "  - Utilização de prompt padrão para classificar texto como positivo, neutro ou negativo se não houver input do usuário\n",
      "  - Exibição do resultado da classificação no DataFrame\n",
      "- **Referências importantes**:\n",
      "  - [[hub-llm]]\n",
      "  - [[hub-python]]\n",
      "  - [[Atlas/02_CONCEPT/criando-variaveis-(colunas)-em-um-dataframe.md|criando-variaveis-(colunas)-em-um-dataframe]]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🗓️ Data: 2025-05-02\n",
      "====================================================================================================\n",
      "\n",
      "📄 Resumo do arquivo: snip-andas-groupby-function.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **Principais tópicos**:\n",
      "  - Criar agrupamento de variáveis em um DataFrame usando Pandas.\n",
      "\n",
      "- **Ideias centrais ou insights**:\n",
      "  - O código apresentado demonstra como utilizar a função `groupby` do Pandas para agrupar variáveis em um DataFrame.\n",
      "\n",
      "- **Referências importantes**:\n",
      "  - [Documentação oficial do Pandas sobre a função `groupby`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)\n",
      "  - Conexão com o tópico \"[[grouping-data-by-category-in-pandas]]\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📄 Resumo do arquivo: snip-get-dataframe-info.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **Principais tópicos**\n",
      "    - Obtenção de informações básicas de um dataframe.\n",
      "    - Dimensões, tipos de dados, valores nulos, valores únicos e estatísticas descritivas.\n",
      "  \n",
      "- **Ideias centrais ou insights**\n",
      "    - O código fornece um relatório informativo sobre um DataFrame, incluindo dimensões, tipos de dados, valores nulos, valores únicos e estatísticas descritivas.\n",
      "  \n",
      "- **Referências importantes**\n",
      "    - [[hub-tratamento-de-dados]]\n",
      "    - [[hub-jupyterNotebook]]\n",
      "    - [[Extraindo informacoes dados]]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📄 Resumo do arquivo: snip-listar-diretorios-os.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **Título**: Listar todos os arquivos em um diretório\n",
      "- **Principais tópicos**: \n",
      "  - Propósito de listar arquivos em um diretório\n",
      "  - Código em Python para listar arquivos\n",
      "  - Tratamento de exceções para diretório não encontrado ou permissão negada\n",
      "- **Ideias centrais ou insights**: \n",
      "  - O código em Python apresentado permite listar todos os arquivos em um diretório especificado.\n",
      "  - É possível filtrar apenas os arquivos, excluindo os diretórios.\n",
      "  - São tratadas exceções para casos de diretório não encontrado, permissão negada e outros erros inesperados.\n",
      "- **Referências importantes**: \n",
      "  - Conexão com o arquivo [[Atlas/05_DOC/doc-pandas-methods.md|doc-pandas-methods]]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📄 Resumo do arquivo: snip-obter-percentual-valores-df.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **Propósito:** Obter valores percentuais e proporções do DataFrame.\n",
      "- **Códigos:** Utilização das funções `value_counts` e `cut` do Pandas para calcular percentuais por faixa.\n",
      "- **Ideias centrais:** A função `calcular_percentual_por_faixa` categoriza os dados em intervalos, calcula o percentual de ocorrências em cada categoria e retorna os percentuais arredondados.\n",
      "- **Referências importantes:** Uso do Pandas para manipulação e análise de dados.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import textwrap\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# ========================\n",
    "# CONFIGURAÇÕES\n",
    "# ========================\n",
    "\n",
    "openai.api_key = input('api key') # substitua pela sua chave\n",
    "CAMINHO_PASTA = input('path')\n",
    "MAX_CHARS = 4000\n",
    "\n",
    "# ========================\n",
    "# FUNÇÕES UTILITÁRIAS\n",
    "# ========================\n",
    "\n",
    "def coletar_markdowns(diretorio_base):\n",
    "    arquivos_md = []\n",
    "    for raiz, _, arquivos in os.walk(diretorio_base):\n",
    "        for arquivo in arquivos:\n",
    "            if arquivo.endswith(\".md\"):\n",
    "                caminho_completo = os.path.join(raiz, arquivo)\n",
    "                data_modificacao = datetime.fromtimestamp(os.path.getmtime(caminho_completo)).date()\n",
    "                arquivos_md.append({\n",
    "                    \"caminho\": caminho_completo,\n",
    "                    \"data\": data_modificacao\n",
    "                })\n",
    "    return arquivos_md\n",
    "\n",
    "def carregar_conteudo_arquivos(lista_arquivos):\n",
    "    conteudos = []\n",
    "    for item in lista_arquivos:\n",
    "        caminho = item[\"caminho\"]\n",
    "        try:\n",
    "            with open(caminho, 'r', encoding='utf-8') as f:\n",
    "                conteudos.append({\n",
    "                    \"caminho\": caminho,\n",
    "                    \"data\": item[\"data\"],\n",
    "                    \"conteudo\": f.read()\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao ler {caminho}: {e}\")\n",
    "    return conteudos\n",
    "\n",
    "def resumir_com_openai(texto, caminho, parte=None):\n",
    "    titulo_arquivo = os.path.basename(caminho)\n",
    "    parte_info = f\" (Parte {parte})\" if parte else \"\"\n",
    "    prompt = textwrap.dedent(f\"\"\"\n",
    "        Você é um assistente que resume arquivos Markdown de forma objetiva e concisa.\n",
    "        Resuma brevemente o conteúdo do arquivo: **{titulo_arquivo}{parte_info}**.\n",
    "\n",
    "        Formato do resumo:\n",
    "        - **Título** (se houver)\n",
    "        - **Principais tópicos**\n",
    "        - **Ideias centrais ou insights**\n",
    "        - **Referências importantes (se houver)**\n",
    "        \n",
    "        Seja direto, use frases curtas e foque apenas no essencial.\n",
    "\n",
    "        Texto:\n",
    "        {texto}\n",
    "    \"\"\")\n",
    "\n",
    "    try:\n",
    "        resposta = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Você é um assistente que resume arquivos Markdown com precisão e concisão.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=400  # Resumo mais curto\n",
    "        )\n",
    "        return resposta['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        return f\"[ERRO AO CONSULTAR LLM]: {e}\"\n",
    "\n",
    "\n",
    "def dividir_texto(texto, max_chars):\n",
    "    partes = []\n",
    "    while len(texto) > max_chars:\n",
    "        corte = texto[:max_chars].rfind(\"\\n\\n\")\n",
    "        if corte == -1:\n",
    "            corte = max_chars\n",
    "        partes.append(texto[:corte])\n",
    "        texto = texto[corte:]\n",
    "    partes.append(texto)\n",
    "    return partes\n",
    "\n",
    "def processar_arquivo(item):\n",
    "    caminho = item[\"caminho\"]\n",
    "    texto = item[\"conteudo\"]\n",
    "\n",
    "    partes = dividir_texto(texto, MAX_CHARS)\n",
    "    resumos_parciais = []\n",
    "\n",
    "    for idx, parte in enumerate(partes):\n",
    "        resumo = resumir_com_openai(parte, caminho, parte=(idx+1) if len(partes) > 1 else None)\n",
    "        resumos_parciais.append(resumo)\n",
    "\n",
    "    if len(resumos_parciais) > 1:\n",
    "        resumo_final = resumir_com_openai(\"\\n\\n\".join(resumos_parciais), caminho)\n",
    "    else:\n",
    "        resumo_final = resumos_parciais[0]\n",
    "\n",
    "    return resumo_final\n",
    "\n",
    "# ========================\n",
    "# MAIN\n",
    "# ========================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🔍 Coletando arquivos Markdown...\")\n",
    "    arquivos = coletar_markdowns(CAMINHO_PASTA)\n",
    "    print(f\"✅ {len(arquivos)} arquivos encontrados.\\n\")\n",
    "\n",
    "    conteudos = carregar_conteudo_arquivos(arquivos)\n",
    "\n",
    "    # Agrupar arquivos por data\n",
    "    arquivos_por_data = defaultdict(list)\n",
    "    for item in conteudos:\n",
    "        arquivos_por_data[item[\"data\"]].append(item)\n",
    "\n",
    "    # Ordenar por data decrescente\n",
    "    datas_ordenadas = sorted(arquivos_por_data.keys(), reverse=True)\n",
    "\n",
    "    for data in datas_ordenadas:\n",
    "        print(f\"\\n🗓️ Data: {data}\")\n",
    "        print(\"=\" * 100)\n",
    "        for item in arquivos_por_data[data]:\n",
    "            print(f\"\\n📄 Resumo do arquivo: {os.path.basename(item['caminho'])}\")\n",
    "            print(\"-\" * 80)\n",
    "            resumo = processar_arquivo(item)\n",
    "            print(resumo)\n",
    "            print(\"\\n\" + \"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4285c7f-0b88-487a-8e9b-ac9ce2f6c49e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
